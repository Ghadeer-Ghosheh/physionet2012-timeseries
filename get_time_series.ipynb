{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYob4r3seIBr"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import ujson as json\n",
        "import dill\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUcPGD02ZBif"
      },
      "outputs": [],
      "source": [
        "# select the physiological time-series variables to be extracted (35 variables)\n",
        "variables = ['ALP','HR', 'DiasABP','Na', 'Lactate', 'NIDiasABP', 'PaO2', 'WBC', 'pH', 'Albumin', 'ALT', 'Glucose', 'SaO2',\n",
        "              'Temp', 'AST', 'Bilirubin', 'BUN', 'RespRate', 'Mg', 'HCT', 'SysABP', 'FiO2', 'K', 'GCS',\n",
        "              'Cholesterol', 'NISysABP', 'TroponinT', 'MAP', 'TroponinI', 'PaCO2', 'Platelets', 'Urine', 'NIMAP',\n",
        "              'Creatinine','HCO3' ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGBGDBw_ZJLl"
      },
      "source": [
        "Get patient ids and outcomes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8VaGoK0ZYuL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def extract_interventions(patient_record, intervention_str):\n",
        "    \"\"\" this function gets available intervention adminstration data for the chosen patient record \"\"\"\n",
        "    patient_record = patient_record.set_index('Parameter').to_dict()['Value']\n",
        "    intervention_values = []\n",
        "    for recording in [intervention_str]:\n",
        "        if (recording in patient_record):\n",
        "            intervention_values.append(patient_record[recording])\n",
        "        else:\n",
        "            intervention_values.append(np.nan)\n",
        "    return intervention_values\n",
        "\n",
        "\n",
        "def extract_observations(patient_record, variables):\n",
        "    \"\"\" this function gets available observations for each of the variables /per chosen patient record \"\"\"\n",
        "    data = []\n",
        "    patient_record = patient_record.set_index('Parameter').to_dict()['Value']\n",
        "    for recording in variables:\n",
        "        if (recording in patient_record):\n",
        "            data.append(patient_record[recording])\n",
        "        else:\n",
        "            data.append(np.nan)\n",
        "    return data\n",
        "\n",
        "def group_time_hr(value):\n",
        "    \"\"\" this function groups the observations per hour \"\"\"\n",
        "    hours, _ = map(int, value.split(':'))\n",
        "    return hours\n",
        "\n",
        "def get_dictionary(values, intervention):\n",
        "    \"\"\" this function creates a data dictionary for each of the patient's data \"\"\"\n",
        "    m = pd.DataFrame(values)\n",
        "    dictionary = {}\n",
        "    dictionary[\"intervention\"] = intervention\n",
        "    dictionary['raw'] = values\n",
        "    return dictionary\n",
        "\n",
        "def myconverter(obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        elif isinstance(obj, datetime.datetime):\n",
        "            return obj.__str__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgIjgWnfQck7"
      },
      "outputs": [],
      "source": [
        "def extract_patient_record_ts(id_,set_name,time_length,variables):\n",
        "    \"\"\"this function creates the patient dictionary from the txt files \"\"\"\n",
        "    f_name = set_name+\"/\"+ str(id_)+\".txt\"\n",
        "    data = pd.read_csv(f_name)\n",
        "    data['Time'] = data['Time'].apply(lambda x: group_time_hr(x))\n",
        "\n",
        "    raw = []\n",
        "    intervention= []\n",
        "    for h in range(time_length):\n",
        "        raw.append(extract_observations(data[data['Time'] == h],variables))\n",
        "        intervention.append(extract_interventions(data[data['Time'] == h],\"MechVent\"))\n",
        "    \n",
        "    raw = np.array(raw)\n",
        "    patient_dictionary = {'id': id_}\n",
        "    patient_dictionary[\"data\"] = get_dictionary(raw,intervention)\n",
        "    patient_dictionary = json.dumps(patient_dictionary,default=myconverter)\n",
        "    return(patient_dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvmelRlYuErZ"
      },
      "outputs": [],
      "source": [
        "def data_to_tensors(json_file_name, set_name, time_length, record_ids,variables):\n",
        "    \"\"\" extract the data for the records in the chosen set folder and convert them to tensors\"\"\"\n",
        "    json_file = open(json_file_name, 'w')\n",
        "    for id_ in tqdm(record_ids):\n",
        "            json_file.write(extract_patient_record_ts(id_,set_name,time_length,variables) + '\\n')\n",
        "    json_file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJLI__6NTD8S"
      },
      "outputs": [],
      "source": [
        "def load_tensors(filename):\n",
        "    \"\"\" this function  loads the json files with extracted/formatted data into two components, intervention and physiological data\"\"\"\n",
        "    Data_raw = []\n",
        "    Interventions =[]\n",
        "\n",
        "    for i in open(filename):\n",
        "        data_raw = json.loads(i)[\"data\"][\"raw\"]\n",
        "        interv = json.loads(i)[\"data\"][\"intervention\"]\n",
        "\n",
        "        Interventions.append(interv)\n",
        "        Data_raw.append(data_raw)\n",
        "    \n",
        "    Interventions = np.array(Interventions)\n",
        "    Data_raw =np.array(Data_raw)\n",
        "\n",
        "    return(Data_raw,Interventions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load extracted ids and outcomes"
      ],
      "metadata": {
        "id": "rC5dnVIMHU2N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE8fukjAkFO0"
      },
      "outputs": [],
      "source": [
        "ids_a = pd.read_pickle(\"extracts/ids_set_a.pkl\")\n",
        "ids_b = pd.read_pickle(\"extracts/ids_set_b.pkl\")\n",
        "ids_c = pd.read_pickle(\"extracts/ids_set_c.pkl\")\n",
        "outcomes_a = pd.read_pickle(\"extracts/outcomes_set_a.pkl\")\n",
        "outcomes_b = pd.read_pickle(\"extracts/outcomes_set_b.pkl\")\n",
        "outcomes_c = pd.read_pickle(\"extracts/outcomes_set_c.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_a.sort()\n",
        "ids_b.sort()\n",
        "ids_c.sort()"
      ],
      "metadata": {
        "id": "7pnnpA1JA9xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_steps_to_extract = 48"
      ],
      "metadata": {
        "id": "MHn9MVP3ME3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIq-3t1ykFVG"
      },
      "outputs": [],
      "source": [
        "data_to_tensors(\"set_a\",\"set-a\",time_steps_to_extract, ids_a,variables)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_to_tensors(\"set_b\",\"set-b\",time_steps_to_extract, ids_b, variables)"
      ],
      "metadata": {
        "id": "7QjZKoMwIwov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_to_tensors(\"set_c\",\"set-c\",time_steps_to_extract, ids_c,variables)"
      ],
      "metadata": {
        "id": "yobpymQ2Iwyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0My6XLhkFYl"
      },
      "outputs": [],
      "source": [
        "raw_data_a,interventions_a =load_tensors(\"set_a\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_b,interventions_b =load_tensors(\"set_b\")"
      ],
      "metadata": {
        "id": "TWRmmVV5Ih8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_c,interventions_c =load_tensors(\"set_c\")"
      ],
      "metadata": {
        "id": "67pVcr4rIiIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export files"
      ],
      "metadata": {
        "id": "AOcQJGE3YED4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('extracts/3d_tensor_set_a.pkl', 'wb') as outfile:\n",
        "    dill.dump(raw_data_a, outfile, pickle.HIGHEST_PROTOCOL) \n",
        "with open('extracts/3d_tensor_set_b.pkl', 'wb') as outfile:\n",
        "    dill.dump(raw_data_b, outfile, pickle.HIGHEST_PROTOCOL) \n",
        "with open('extracts/3d_tensor_set_c.pkl', 'wb') as outfile:\n",
        "    dill.dump(raw_data_c, outfile, pickle.HIGHEST_PROTOCOL) \n"
      ],
      "metadata": {
        "id": "8UpnW0osIiRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('extracts/interventions_a.pkl', 'wb') as outfile:\n",
        "    dill.dump(interventions_a, outfile, pickle.HIGHEST_PROTOCOL) \n",
        "with open('extracts/interventions_b.pkl', 'wb') as outfile:\n",
        "    dill.dump(interventions_b, outfile, pickle.HIGHEST_PROTOCOL) \n",
        "with open('extracts/interventions_c.pkl', 'wb') as outfile:\n",
        "    dill.dump(interventions_c, outfile, pickle.HIGHEST_PROTOCOL) \n"
      ],
      "metadata": {
        "id": "6IAfb_EXWjxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJ4OmJbtfEoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZEbRfCjFFWb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
